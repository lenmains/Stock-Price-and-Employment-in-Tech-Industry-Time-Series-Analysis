

import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.regression.LinearRegression

val spark = SparkSession.builder.appName("LinearRegression").getOrCreate()

val df = spark.read.option("header", "true").csv("year_ep.csv")
val df1 = df.withColumn("emp_n", col("employment").cast("double"))

val df2 = df1.withColumn("year_n", col("year").cast ("int")).select ("year_n", "emp_n")
val assembler = new VectorAssembler().setInputCols(Array("year_n")).setOutputCol("new_col")

val lr_model = new LinearRegression().setLabelCol("emp_n"). setFeaturesCol ("new_col")
val df3 = assembler.transform(df2)
val lr_model1 = lr_model.fit(df3)

println(s"Coefficients: ${lr_model1.coefficients} Intercept: ${lr_model1.intercept}")
val trainingSummary = lr_model1.summary
trainingSummary.residuals.show()


println(s"r2: ${trainingSummary.r2}")
println(s"RMSE: ${trainingSummary.rootMeanSquaredError}")